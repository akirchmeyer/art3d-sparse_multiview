{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pdb\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append('pix2pix-zero/src')\n",
    "sys.path.append('pix2pix-zero/src/utils')\n",
    "from utils.ddim_inv import DDIMInversion\n",
    "from utils.scheduler import DDIMInverseScheduler\n",
    "from types import SimpleNamespace \n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import argparse\n",
    "\n",
    "cls = 'dog'\n",
    "args = {\n",
    "    'input_image': f'/grogu/user/akirchme/art3d_sd_webui/fg/{cls}/',\n",
    "    'results_folder': f'/grogu/user/akirchme/art3d_sd_webui/inversion/{cls}',\n",
    "    'num_ddim_steps': 100,\n",
    "    'model_path': 'stabilityai/stable-diffusion-2-1-base',\n",
    "    'use_float_16': False,\n",
    "    'prompt': f'{cls}'\n",
    "}\n",
    "\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "torch_dtype = torch.float16 if args.use_float_16 else torch.float32   \n",
    "#pipe = DDIMInversion.from_pretrained(args.model_path, torch_dtype=torch_dtype).to(\"cuda\")\n",
    "#pipe.scheduler = DDIMInverseScheduler.from_config(pipe.scheduler.config)\n",
    "    \n",
    "def generate_inversion(args):\n",
    "    # make the output folders\n",
    "    os.makedirs(args.results_folder, exist_ok=True)\n",
    "\n",
    "    # if the input is a folder, collect all the images as a list\n",
    "    if os.path.isdir(args.input_image):\n",
    "        l_img_paths = sorted(glob(os.path.join(args.input_image, \"*.png\")))\n",
    "    else:\n",
    "        l_img_paths = [args.input_image]\n",
    "\n",
    "    for img_path in l_img_paths:\n",
    "        bname = os.path.basename(img_path).split(\".\")[0]\n",
    "        res_path = os.path.join(args.results_folder, f\"{bname}.pt\")\n",
    "        if os.path.exists(res_path):\n",
    "            continue\n",
    "        img = Image.open(img_path).resize((512,512), Image.Resampling.LANCZOS)\n",
    "        res = pipe(\n",
    "            args.prompt, \n",
    "            guidance_scale=1,\n",
    "            num_inversion_steps=args.num_ddim_steps,\n",
    "            img=img,\n",
    "            torch_dtype=torch_dtype,\n",
    "            return_intermediate=True\n",
    "        )\n",
    "        # save the inversion\n",
    "        torch.save(res, res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_inversion(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, DDIMScheduler, DPMSolverMultistepScheduler\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-2-1-base').to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{os.path.basename(x) : torch.load(x).shape for x in list(sorted(glob(os.path.join(args.results_folder, \"*.pt\"))))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd3602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decode_latents(vae, latents):\n",
    "    latents = 1 / 0.18215 * latents\n",
    "    image = vae.decode(latents).sample\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    # we always cast to float32 as this does not cause significant overhead and is compatible with bfloa16\n",
    "    image = image.detach().cpu().permute(0, 2, 3, 1).float().numpy()\n",
    "    return image\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0,0].imshow(decode_latents(pipe.vae, x_inv[0:1].cuda()).squeeze())\n",
    "axs[0,1].imshow(decode_latents(pipe.vae, x_inv[-1:].cuda()).squeeze())\n",
    "axs[1,0].imshow(x_inv[0,:3,:,:].permute(1,2,0))\n",
    "axs[1,1].imshow(x_inv[-1,:3,:,:].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inv[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e2eb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prompt = 'photo of a dog, far, side view'\n",
    "neg_prompt = 'drawing, shiny'\n",
    "for path in list(sorted(glob(os.path.join(args.results_folder, \"*.pt\")))):\n",
    "    bname = os.path.basename(path).split(\".\")[0]\n",
    "    x_inv = torch.load(os.path.join(args.results_folder, f\"{bname}.pt\"))\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "    axs[0].imshow(Image.open(f'/grogu/user/akirchme/art3d_sd_webui/fg/{cls}/{bname}.png'))\n",
    "    pipe.scheduler = DDIMScheduler.from_pretrained('stabilityai/stable-diffusion-2-1-base', subfolder='scheduler')\n",
    "    axs[1].imshow(pipe(latents=x_inv[-1].unsqueeze(0), prompt=prompt, negative_prompt=neg_prompt).images[0])\n",
    "    #axs[2].imshow(pipe(latents=x_inv[].unsqueeze(0), prompt='dog', num_inference_steps=100).images[0])\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_pretrained('stabilityai/stable-diffusion-2-1-base', subfolder='scheduler')\n",
    "    axs[2].imshow(pipe(latents=x_inv[-1].unsqueeze(0), prompt=prompt, negative_prompt=neg_prompt).images[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc44c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
